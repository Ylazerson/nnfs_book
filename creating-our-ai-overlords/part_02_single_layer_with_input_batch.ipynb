{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part_02_single_layer_with_input_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Code Dependencies"
      ],
      "metadata": {
        "id": "Hstmig2N3nM2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1PmeaqP1LMU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from IPython.display import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication is all you need"
      ],
      "metadata": {
        "id": "WjFughnplVGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start off with a quote from the famous/infamous [Mark Saroufim](https://marksaroufim.substack.com/) in his post [Machine Learning: The Great Stagnation](https://towardsdatascience.com/machine-learning-the-great-stagnation-3a0f044e17e0)\n",
        "\n",
        "> I often get asked by young students new to Machine Learning, what math do I need to know for Deep Learning and my answer is Matrix Multiplication and Derivatives of square functions. \n",
        ">\n",
        "> LSTMs a bunch of matrix multiplications, Transformers a whole bunch of matrix multiplications, CNNs use convolutions which are a generalization of matrix multiplication.\n",
        "> \n",
        "> Deep Neural Networks are a composition of matrix multiplications with the occasional non-linearity in between.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1CMOpPOEPSqHL3N_CCjD4Ms94xxQJdEeP)\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "rkDgEhhAlaE8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYAaDzAEywC4"
      },
      "source": [
        "## Dot Product and Vector Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When multiplying **vectors**, you either perform a **dot product** or a **cross product**. \n",
        "\n",
        "A **cross product** results in a **vector** while a **dot product** results in a **scalar** (a single value/number)."
      ],
      "metadata": {
        "id": "Jct4XjYJ0BLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Product"
      ],
      "metadata": {
        "id": "-wM_qohF0BjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross product is defined only for two 3-element vectors, and the result is another 3-element vector. \n",
        "\n",
        "That's as far as we're going to go with the Cross Product; it is very rarely used in machine-learning (I have never seen it used)."
      ],
      "metadata": {
        "id": "UvSi8ujj0F2U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bO4SkpB1a-Z"
      },
      "source": [
        "### Dot Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5ZYUqPmyz7E"
      },
      "source": [
        "\n",
        "Dot product of two vectors:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1QrMzksXFeQvkCO5ksHXm7N6kwoj1xcIf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHTMZcWjz5Uc"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "b = [2, 3, 4]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRaKkHI00I-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f440fe-e3b3-439c-ee49-786410b9aec5"
      },
      "source": [
        "dot_product = (a[0] * b[0]) + (a[1] * b[1]) + (a[2] * b[2])\n",
        "\n",
        "dot_product"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNTF_JFD1qLz"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "### Dot Product using Numpy\n",
        "\n",
        "![](https://drive.google.com/uc?id=1g5r9kZpdgzbcInSwi88VEONi-O0wIjnl)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xd93Qvh1xOW"
      },
      "source": [
        "inputs  = [1.0, 2.0,  3.0]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbvnDizQ2B8H",
        "outputId": "0e35f670-4167-46c5-d35b-1c53aa901158"
      },
      "source": [
        "dot_product = np.dot(weights, inputs)\n",
        "dot_product"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30000000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gupJvvas2Kj_",
        "outputId": "6144fbfc-e02f-4879-e994-9b83407fe132"
      },
      "source": [
        "output = dot_product + bias\n",
        "output"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRb7W_pxzyJY"
      },
      "source": [
        "### Vector Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f7RPg6UzEt4"
      },
      "source": [
        "The **addition** of the two **vectors**: \n",
        "- is performed **element-wise**\n",
        "- both vectors have to be of the same size\n",
        "- the result is a vector of this size as well\n",
        "\n",
        "![](https://drive.google.com/uc?id=1eZ-KV1T62fJci_7een4iqcBliuNOlsmG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owcOuGr_07Bu"
      },
      "source": [
        "a = np.array([1, 2, 3])\n",
        "b = np.array([2, 3, 4])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRnONMYm1PWq",
        "outputId": "1537d023-47cf-4c92-d78f-46118168c217"
      },
      "source": [
        "added_vectors = a + b\n",
        "\n",
        "added_vectors"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfTRkaKk0_je"
      },
      "source": [
        "## A Layer of Neurons with NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCGkgcdm3JxM"
      },
      "source": [
        "Let's calculate the output of a layer of 3 neurons, which means the weights will be a matrix or list of weight vectors.\n",
        "\n",
        "NumPy makes this very easy for us - treating this **matrix** as a list of vectors and performing the dot product **one by one** with the vector\n",
        "of inputs, returning a list of dot products."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://drive.google.com/uc?id=1kEKnaz_iPO5jfhijnrYSCbFsH0oBAR_-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "YrXs3OIaBvMa",
        "outputId": "84337af1-2fa6-4dc5-bf34-b4547dcc07dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/uc?id=1kEKnaz_iPO5jfhijnrYSCbFsH0oBAR_-\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs78pg8N22Ro"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1t8aEIpA1liIbOJd61fp1uwFOWZW06Kq8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fir-etX27Es"
      },
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pWZ-k7h3tE1"
      },
      "source": [
        "weights = [\n",
        "    [0.2, 0.8, -0.5, 1.0],\n",
        "    [0.5, -0.91, 0.26, -0.5],\n",
        "    [-0.26, -0.27, 0.17, 0.87]\n",
        "]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCaOI8K4DYf"
      },
      "source": [
        "biases = [2.0, 3.0, 0.5]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfBAkbt94I9b",
        "outputId": "413eb0d9-062f-40b9-f5e9-3143437d8689"
      },
      "source": [
        "dot_product = np.dot(weights, inputs)\n",
        "dot_product"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.8  , -1.79 ,  1.885])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP0B-BXp4QM-",
        "outputId": "beb979db-8806-4bd2-fb35-64663b383dda"
      },
      "source": [
        "output = dot_product + biases\n",
        "output "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.8  , 1.21 , 2.385])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYOPdAt34X7m"
      },
      "source": [
        "## A Batch of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m30_NwQa4pW8"
      },
      "source": [
        "To train, neural networks tend to receive data in **batches**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdCugcej45AQ"
      },
      "source": [
        "inputs = [\n",
        "    [1.0, 2.0, 3.0, 2.5],\n",
        "    [2.0, 5.0, -1.0, 2.0],\n",
        "    [-1.5, 2.7, 3.3, -0.8]\n",
        "]\n",
        "\n",
        "weights = [\n",
        "    [0.2, 0.8, -0.5, 1.0],\n",
        "    [0.5, -0.91, 0.26, -0.5],\n",
        "    [-0.26, -0.27, 0.17, 0.87]\n",
        "]\n",
        "\n",
        "biases = [2.0, 3.0, 0.5]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLtRjKEz4_1x"
      },
      "source": [
        "We have a **matrix** of inputs and a **matrix** of weights now, and we need to perform the **dot product** on them somehow, but how? \n",
        "\n",
        "In this example, we need to manage both **matrices** as lists of vectors and perform dot products on all of them in all combinations, resulting in a list of lists of outputs, or a matrix; this operation is called the **matrix product**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOGosnjt5tSO"
      },
      "source": [
        "### Matrix Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tfoSXg6Zaj"
      },
      "source": [
        "The **matrix product**: \n",
        "- an operation with **2 matrices** \n",
        "- we are performing **dot products** of all combinations of **rows from the first matrix** and the **columns of the 2nd matrix**\n",
        "- result in a matrix of those atomic dot products\n",
        "- the size of the 2nd dimension of the left matrix must match the size of the 1st dimension of the right matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://drive.google.com/uc?id=1IXQkoZKctjqavIKl7S_CiJkpVE_eD5m-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "SToLh-tIFTNM",
        "outputId": "cb25a8fd-d365-4d3c-eb64-5cd546aafb9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/uc?id=1IXQkoZKctjqavIKl7S_CiJkpVE_eD5m-\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIog6N73-blB"
      },
      "source": [
        "### Transposition for the Matrix Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEEN9iyq-x22"
      },
      "source": [
        "**Transposition** simply modifies a matrix in a way that its rows become columns and columns become rows.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1g__BDqNR2iw2IGrW5hoRZTXtKiIcYofj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqAVwMK__PB2"
      },
      "source": [
        "### Behind the scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wguxff7kBgzW"
      },
      "source": [
        "#### row-vector-matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVrYYFTjAUFl"
      },
      "source": [
        "A **row-vector-matrix** is a matrix whose first dimension’s size equals 1 and the\n",
        "second dimension’s size equals `n` - the vector size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6i78LeLAksN",
        "outputId": "779ca85c-545e-4216-de81-e2d0b971e93a"
      },
      "source": [
        "# Note the double brackets:\n",
        "a = np.array(\n",
        "    [\n",
        "        [1, 2, 3]\n",
        "    ]\n",
        ")\n",
        "\n",
        "a"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VBz2Ov2GTdl",
        "outputId": "0074f862-081c-4ab2-a64e-02f134634a75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aFOw1wvAtBq",
        "outputId": "611b7dea-8db5-424a-bb2e-900c19b8537a"
      },
      "source": [
        "# Or, alternatively:\n",
        "a = np.array(\n",
        "    [1, 2, 3]\n",
        ")\n",
        "\n",
        "np.expand_dims(a, axis=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFV9T8h5BjGP"
      },
      "source": [
        "#### column-vector-matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPAVv9iDA-PO"
      },
      "source": [
        "A **column-vector-matrix** is a matrix where the 2nd dimension’s size equals 1, in other words, it’s an array of shape `(n, 1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqLPCFlaBSEe",
        "outputId": "2ec10bc1-2d71-48ea-87e3-c1ef0a0ad7a0"
      },
      "source": [
        "a = np.array([[1, 2, 3]]).T\n",
        "\n",
        "a"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY2s4zYlGhMq",
        "outputId": "c4e49aeb-5dc4-4c59-964f-1d50971dc49f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwX9WolhBXK_"
      },
      "source": [
        "#### Dot product of row-vector-matrix and column-vector-matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO_aPfAqBt23",
        "outputId": "c63db3f3-040b-4c19-8357-b7d80c32553d"
      },
      "source": [
        "a = np.array([[1, 2, 3]])\n",
        "b = np.array([[2, 3, 4]]).T\n",
        "\n",
        "np.dot(a, b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLkZ_R97Fs7"
      },
      "source": [
        "> We have achieved the same result as the dot product of two vectors, but performed on matrices and returning a matrix.\n",
        "\n",
        "It’s worth mentioning that NumPy does not have a dedicated method for performing matrix product - the dot product and\n",
        "matrix product are both implemented in a single method: `np.dot()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ2Yfa_MCHk8"
      },
      "source": [
        "## Final Code - Single Layer with Input Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1uRg9EgXNh1hhUvMk6IXZaoVxkSL8C7p4)"
      ],
      "metadata": {
        "id": "e0EMD6RJKU9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://drive.google.com/uc?id=1FbELp4cIr94IcgrdQVqX9s6CZ4BmvkPd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "oHDpVipNJBFh",
        "outputId": "0f1e3878-546c-4a95-fd98-d50909379e11"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/uc?id=1FbELp4cIr94IcgrdQVqX9s6CZ4BmvkPd\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url='https://drive.google.com/uc?id=1U6Lr6JmtFZfVtDIDxSNWOV6rjToRtTjq')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "7NE3_zijJRpP",
        "outputId": "2ac52c07-aee2-4bbf-b391-62eb39e837f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/uc?id=1U6Lr6JmtFZfVtDIDxSNWOV6rjToRtTjq\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5GzlzSaCRno"
      },
      "source": [
        "inputs = [\n",
        "    [1.0, 2.0, 3.0, 2.5],\n",
        "    [2.0, 5.0, -1.0, 2.0],\n",
        "    [-1.5, 2.7, 3.3, -0.8]\n",
        "]\n",
        "\n",
        "weights = [\n",
        "    [0.2, 0.8, -0.5, 1.0],\n",
        "    [0.5, -0.91, 0.26, -0.5],\n",
        "    [-0.26, -0.27, 0.17, 0.87]\n",
        "]\n",
        "\n",
        "biases = [2.0, 3.0, 0.5]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HQoeUNNC61H",
        "outputId": "1839637e-34ce-4b11-d947-e2a1d1ec7b60"
      },
      "source": [
        "dot_product = np.dot(\n",
        "    inputs, \n",
        "    np.array(weights).T\n",
        ")\n",
        "\n",
        "dot_product"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.8  , -1.79 ,  1.885],\n",
              "       [ 6.9  , -4.81 , -0.3  ],\n",
              "       [-0.59 , -1.949, -0.474]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-so9j9kCd71",
        "outputId": "3740e458-0b4b-4f93-83ff-6c5c17844d7d"
      },
      "source": [
        "layer_outputs = dot_product + biases\n",
        "\n",
        "layer_outputs"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.8  ,  1.21 ,  2.385],\n",
              "       [ 8.9  , -1.81 ,  0.2  ],\n",
              "       [ 1.41 ,  1.051,  0.026]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOmRF7avDED2"
      },
      "source": [
        "> **Important Note:** \n",
        "> \n",
        "> The 2nd argument for `np.dot()` is our transposed weights. Previously it was the inputs. \n",
        "> \n",
        "> As we’ll soon learn, it’s more useful to have a result consisting of a list of layer **outputs per each sample** than **outputs per each neuron**.\n",
        ">\n",
        "> We want the resulting array to be **sample-related** and not **neuron-related**. We want it this way being that, as we pass those samples further through the network, the next layer(s) will expect a batch of inputs.\n",
        "\n"
      ]
    }
  ]
}