{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_backpropagation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAr-bE-3iUsV"
      },
      "source": [
        "# B\"H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3QBNHH3iWWf"
      },
      "source": [
        "## Categorical Cross-Entropy Loss Derivative\n",
        "\n",
        "\n",
        "We will not go thru the mathematical derivation of the Categorical Cross-Entropy loss here. \n",
        "\n",
        "Perhaps later this will be done here thoroughly. See the book, pages 215-219, for details. \n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "Over here, we'll cut to the chase.\n",
        "\n",
        "The derivative of this loss function **with respect to its inputs** equals the negative ground-truth vector, divided by the vector of the predicted values (which is also the output vector of the softmax function):\n",
        "\n",
        "![](https://drive.google.com/uc?id=14mHq6DyVP8p44UITAq7UyVDxASc6Yhwq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-aXnyrCjOXz"
      },
      "source": [
        "## Softmax Activation Derivative\n",
        "\n",
        "As above, we will not go thru the mathematical derivation of the Softmax Activation here. \n",
        "\n",
        "Perhaps later this will be done here thoroughly. See the book, pages 220-229, for details. \n",
        "\n",
        "Note, the calculation is a bit complicated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry1ZrPpTilHj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}